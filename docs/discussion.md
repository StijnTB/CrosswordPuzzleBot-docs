---
title: Discussion
sidebar_position: 4
---

# Discussion

In this PWS, we aimed to, as our main goal suggests, create a computer-controlled opponent that could play a game of our own version of Wordfeud against a human opponent. After spending more than half a year working towards this goal, we have a product that exists in the public space and that is, in our eyes, finished. This gives us the opportunity to look back on the process and product and reflect, as well as cast our eyes upon the future that lies ahead.

## Reflection

Looking back on the conclusion and our original goals, we can say that our main goal was achieved. However, after analysing [the simulation data][matchups_backlink], there is one thing that we want to address: the percentage of games won against Greedy was higher for the Chance bot than for the Combi bot. This is possibly due to the surprisingly low percentage of Boardposition, that being only 40%, dragging the score of the combined Combi bot down. The win-loss ratio of Boardposition against Greedy was also unexpected, as Boardposition was supposed to be an upgrade from the basis Greedy forms. The lower ratio is also explainable though, because the average scores are lower, revealing the more defensive strategy of Boardposition. We also include this issue in the future developments, as the procedure of the bot is not yet fully finished and could benefit greatly from expansion.

Another point of issue for us is a continuation of the aforementioned statement that the Chance bot has a higher win-loss ratio than the Combi bot against Greedy. If we calculate the chance of Combi only winning 56 of 102 games it played using a normal distribution (μ = $$\mu_{\text{Combi}} - \mu_{\text{Greedy}}$$ = 35,549; σ = $$\sqrt{\sigma_{\text{Combi}}^2 + \sigma_{\text{Greedy}}^2}$$  = 95,370) for the chance of winning and a binomial distribution (n = 102; x = 56) for the chance of it winning 56 games or less, we get a chance of 2,8%, a rather low percentage. This chance is in line with our expectations, as beforehand we assumed that the Combi bot, being the most advanced version, would beat Greedy more than Chance did.

One thing that we would do differently if we were to do this project again is take some time at the start of the period to put down the main strategy the final bot should follow. This would help to organise the time we had more effectively as we would be able to more accurately predict how long certain sections of the bot's code would take to develop.

## Future development

After finishing this project, there are still many ways we and other people could build further upon it. If you are interested in continuing what we have started, here are listed some projects that could serve as inspiration. 
* Upgrade efficiency: the bots make their decisions relatively fast, but there is definitely room for improvement there. This path would require a decent level of understanding of the entire codebase, but if you are up for it there is a lot of potential to enhance the user experience.
  * Blank tiles: when a bot is in possession of a blank tile, the time it takes to decide on a move increases drastically, which is less than optimal especially when playing against a human opponent who will recognise this sign and plan their moves accordingly. Reducing this time would hopefully result in a more balanced game between player and bot.
* Endgame strategy: one of the bigger issues the bots have is their lack of specific strategy for the final phase of the game. The reason for this is the big difference in the amount of data the bot has available in the different stages: only in the endgame, which starts when the tilebag is empty, does the bot have full information about the board and the opponent’s tiles. The full information allows for a full simulation of the phase and a perfect play, using an algorithm like Minimax. To achieve this, some optimization would also be necessary to prevent waiting an hour for the bot to finally do something when the game enters the end phase.
* Upgrade the Boardposition bot: due to our fixed time frame, we were unable to perfect the Boardposition bot. We focussed on a few aspects, but there are still many parts of the strategy that fit in this category which we did not flesh out. This path would require the most testing, as the bot relies on a multitude of parameters to create the perfect boardpositionscore based on our analysis. Fine-tuning the parameters is not a task to underestimate, so expect spending a decent amount of time tweaking numbers.
  * Memory: the Boardposition bot currently ‘forgets’ all previous dangerous situations created. This means that it does not take those into account when calculating a degradation score for a new move, even though this plays a major role in real gameplay. Picking up this project would mean creating a register of all tiles and the degradation scores they possess, and adding degradation score calculation to player moves.
  * Specific letter dangers: in this version, the Boardposition bot only bases the danger specific letters form on their playing value. The issue with these playing values which we have not yet addressed is the fact that letters with the same playing value might not be similar in how easily they are used on specific locations on the board. For example, both the S and U have a value of 2, but the S allows for much more interaction when placed on the edge of a board while the U has a bit of an edge in the middle of the board. This project would include statistical analysis of letters to find where they are most often located in words, and combine that with knowledge of the location on the board to generate a more complicated danger factor.
* Upgrade the Chance bot: The main issue of the Chance bot is that it does not work well with a more densely filled board. In this situation, the number of possible bingo moves is severely limited. This results in the bot trading single letters often, in the hope of getting a tilerow which does allow for a bingo, instead of just playing a word that is not a bingo but does reward a decent number of points.
* Analyse statistics: in our reflection, we mentioned that the chance of the Combi bot only winning 56 of its 102 games against Greedy or less lies around 2,8%. Seeing as this is quite low, a possible project could be to simulate a larger number of games and analyse them. Although this is not necessarily a development heavy project, it would allow future developers to gain insights in the improvements their code has on the performance of the bot.

If you have another idea or an addition to one of the projects already mentioned that you want to pitch to us and the community, place a comment under this post in our [GitHub Discussions][github_discussions_ideas]. Please only create an issue on [the repository of this website][github_website_repo_issues] if said issue is about technical error or difficulty with the actual website. Otherwise, we would direct you to the [Issues][github_main_repo_issues] and [Discussions][github_main_repo_discussions] of our main project, so that we can keep everything orderly and running as smoothly as possible.



[github_discussions_ideas]: https://github.com/StijnTB/PWS-2526-CrosswordPuzzleBot/discussions/5
[github_website_repo_issues]: https://github.com/StijnTB/CrosswordPuzzleBot-docs/issues
[github_main_repo_issues]: https://github.com/StijnTB/PWS-2526-CrosswordPuzzleBot/issues
[github_main_repo_discussions]: https://github.com/StijnTB/PWS-2526-CrosswordPuzzleBot/discussions 
[matchups_backlink]: https://stijntb.github.io/CrosswordPuzzleBot-docs/docs/main_project/matchups